{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"dataset.csv\")  # Change to your actual file name\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Transformation/Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())  # Check missing values\n",
    "print(df.dtypes)  # Check data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for pairs of features with High Correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Set correlation threshold\n",
    "threshold = 0.9  # Change to 0.8 if needed\n",
    "\n",
    "# Find highly correlated feature pairs\n",
    "high_corr_features = [(col1, col2, corr_matrix.loc[col1, col2]) \n",
    "                      for col1 in corr_matrix.columns \n",
    "                      for col2 in corr_matrix.columns \n",
    "                      if col1 != col2 and abs(corr_matrix.loc[col1, col2]) > threshold]\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "high_corr_df = pd.DataFrame(high_corr_features, columns=[\"Feature 1\", \"Feature 2\", \"Correlation\"])\n",
    "\n",
    "print(high_corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to decide if we want to commit to a correlation based feature selection, Random Forest Feature Importance Selection, or some other form of feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi_Square Test (For Categorical Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"target\"])  # Features\n",
    "y = df[\"target\"]  # Target variable\n",
    "\n",
    "# Select top 5 features based on chi-square test\n",
    "chi_selector = SelectKBest(score_func=chi2, k=5)\n",
    "X_selected = chi_selector.fit_transform(X, y)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X.columns[chi_selector.get_support()]\n",
    "print(\"Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Feature Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X, y) #For the feature selection, we can use the whole dataset, dont need train-test split\n",
    "\n",
    "# Get feature importance scores\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Convert to DataFrame\n",
    "feature_importance = pd.DataFrame({\"Feature\": X.columns, \"Importance\": importance})\n",
    "feature_importance = feature_importance.sort_values(by=\"Importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative importance\n",
    "feature_importance[\"Cumulative Importance\"] = feature_importance[\"Importance\"].cumsum()\n",
    "\n",
    "# Select features contributing to top 90% importance\n",
    "threshold = 0.90  # Change to 0.95 for 95%\n",
    "selected_features = feature_importance[feature_importance[\"Cumulative Importance\"] <= threshold][\"Feature\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the Feature Importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance[\"Feature\"], feature_importance[\"Importance\"], color=\"skyblue\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance - Random Forest\")\n",
    "plt.gca().invert_yaxis()  # Reverse order to show most important features on top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
